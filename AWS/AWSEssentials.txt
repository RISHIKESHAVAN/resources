Amazon Web Services :-
^^^^^^^^^^^^^^^^^^^
Amazon Elastic Compute Cloud (EC2):
- A virtualised server that runs in AWS DCs. 
- Has a web interface. 
- Complete control over capacity. Windows/Linux
- Steps : 
	> Choose region.
	> Choose Amazon Machine Image (AMI). AMIs are templates of the computers's volumes.
	> Choose instance type. Its a pre configured hardware specification.
	> Configure network, IP, security, storage, tags, key pairs etc
	
Amazon Machine Image (AMI):
- Contains the software configs like OS, app server and apps.
- Possible to create custom AMIs.
- Include a block device mapping to specify the volumes to attach to instance when it is launched.
- Select an AMI based on: 
	> Region 
	> OS 
	> Architecture(32 or 64 bit) 
	> launch permissions - public, explicit or implicit 
	> Storage for root devices 
- Can launch multiple instances of different types from a single AMI

Instance type:
- Determines the hardware of the host computer used for your instance.
- Select instance type based on memory and computing power required for you applications. 
- Instances are deployed in the Amazon EC2 public cloud and the Amazon Virtual private cloud in a Availability zone.
- Networking and security can be configured.
- Can deploy in multiple AZs within a region.

EC2 instance store:
- Only to store temporary data; ephemeral.
- Persists only as long as the instance is alive.

EBS:
- persistent data.
- Independent of instance life; set the 'delete on termination' flag to 'no'

- AMIs are backed by either EBS store or instance store.
- EBS backed - means the root device for the instance is a EBS volume created from a EBS snapshot.
- instance backed - template stored in amazon history.

Instance Lifecycle:
- you can start or stop instances that are only EBS backed
- pending
	> when an AMI is launched, it enters the pending state.
	> moves from the new host computer.
	> the instance type specified at launch determines the hardware of the host
- running
	> AWS uses the AMI specified at launch to boot the instance.
	> billed for each hour or partial hour. billed for all running instances even if they are idle/not connected to
- rebooting
	> Can reboot via console, EC2 cli or API.
	> Recommended to reboot your instance rather than rebooting from operating system
	> When rebooted, instance remains on same host, maintains public DNS, private IPs and instance store data.
	> billing is continuous throughout
	> when you start and stop, host changes
- shutting down
	> stop incurring charges
- terminated
	> instance remains visible for a while on the console after terminated
	> cannot connect or recover a terminated instance
- stopping
	> only EBS backed instances can be stopped
	> enters stopping state then finally stopped
	> hourly usage or data transfer billing stopped 
	> does charge for EBS volume on stopped instances
	> Can modify attributes of a stopped instance like instance time.
	> when stopped and started, instance is moved to pending state and then moved to new host m/c
	> thus we lose all instance store data.
	
Metadata:
- Both instance and user metadata are not protected. Anyone with access to instance can view them. Therefore do not store pwds and sensitive data as user data.
- not billed to retrieve user/instance metadata
Instance Metadata:
- Data about your instance.
- http://169.254.169.254/latest/meta-data
- All metadata are returned as text.
User Metadata:
- Can specify when launching an instance or run a config script.
- can be linux script - executed by cloud-init or a windows batch or PowerShell script - executed by EC2Config 
- limited to 16kb in raw form not base 64 encoded form. data must be base 64 encoded prior to submitting to API.
- User data scripts are run once per instance-id by default. So, user data can also be used to install things like the apache web server.
- So when you stop and start the instance, the scripts are not run.
- http://169.254.169.254/latest/user-data

Amazon S3 (Simple Storage Service):
- simple web services interface to store and retrieve any amount of data, any time from anywhere in the web
- Can store unlimited number of objects in a bucket. 100 bucket limit for an account.
- size of object <5TB. no bucket size limit.
- 99.9999999999% durability and 99.99% availability. durablility - each object is replicated over multiple facilities within a region. So that the object is always there (highly durable). availability - however, as s3 objects are accessed over REST APIs, sometimes these API endpoints maybe down making it unable to access the object. 
- HTTP/S endpoints to store and retrieve data from anywhere in the web
- Highly scalable, reliable, fast and inexpensive.
- Optional server side encryption / AWS Key management service encryption.
- Used to store app files, mp3s, deliveries, snapshots, AMIs.
- Used to make financial transactions using amazon web pay. or to host a website.
- Pricing based on capacity(Gb/month) and bandwith used. into bandwith is free. bandwith out is charged.
- S3 concepts:
	> Stores data as objects. To store- upload the file to S3. while uploading you can set access controls and metadata of the file.
	> An object is composed of a file and any metadata that describes the file.
	> Can control access to buckets and objects.
	> Buckets - logical containers for the objects. Serve different purposes: organise S3 namespaces at highest level, identify account responsible for storage and data transfer charges, play a role in access controls etc. Bucket names are globally unique and mentioned when you create a bucket.
	> Object keys - unique identifier for an object in a bucket. 
					http://doc.s3.amazonaws.com/2006-03-01/AmazonS3.html   
					doc - bucket name  2006-03-01/AmazonS3.html - object key  
					[Optionally, versions can also be used]
	> S3 can be thought of as a basic map between bucket+key+version and the data itself.
	> Control access to buckets and objects using - Access Control Lists(ACLs), Bucket Policies, Identity Access Management(IAM). ACls - to control other AWS accounts. IAM - within your own account. BP - some/all objects within a single bucket.
	> data-transfer - via SSL enabled endpoints. Custom SSLs or Amazon server side encryption.
	> Versioning - a mean of keeping multiple variants of the same object in a bucket. same key but diff versions. Once versioned, an object cannot be unversioned. but can suspend versioning in the bucket.
- Storage classes:
	> Amazon S3 Standard
	> Amazon S3 Standard - Infrequent Access (IA)
	> Glacier
	> Reduced Redundancy Storage
- Lifecycle management: defines how Amazon S3 manages objects during their lifetime. Some objects might have a well-defined lifecycle like eg. log files, archive documents, financial records and long term database backups.
- Case Study: SoundCloud:
	> Operated worldwide.
	> enables users to upload 12 hours of audio material to its platform every minute.
	> Each audio file must be transcoded and stored in multiple formats.
	> Logs and analyzes billions of events.
	> The AWS solution: They use S3 and Glacier. Audio files are distributed to S3 via the SoundCloud website and the infrequently accessed files are moved to Glacier.
- One major drawback: since it is a object level storage type, even if a small part of the object is changed the entire object has to be re-written. eg. changing a character in a word document. So S3 is primarily for write once read many times application.
	
Amazon Elastic Block Store (EBS):
- persistent block level storage volumes offering consistent and low-latency performance.
- Recommended when data changes frequently and requires long term persistence, mainly for database backed apps.
- perfectly suitable for applications that require a database, file system or raw block level storage.
- Snapshots are durable and are automatically replicated within its availability zone.
- EBS volume can be attached to any running instance in the AZ and when done act as storage volumes that function independent of the lifetime of the instance
- When not attached, you only pay the cost of the storage.
- Lifecycle: (Vast amount of unused space) -> Create -> Attach -> Attach and in use -> Create snapshot -> Detach-> (Deleted)
	1> Call CreateVolume 1Gb to 16Gb
	2> Call AttachVolume to affiliate with one EC2 instance
	3> Used by the instance.
	4> Create Snapshot - a photograph of the EBS volume and persist it to S3
	5> Call DetachVolume to detach and attach to a new EC2 instance.
- EBS Magnetic volumes from 1Gb to 1Tb, EBS General purpose(SSD) and Provisional IOPS(SSD) volumes upto 16Gb
- EBS is basically a virtual hard drive. 
- EBS pricing is based on allocated usage, whether you use it or not unlike s3.
- Taking frequent snapshots of your data helps improve the durablility.

EBS vs S3:

+------------------+------------------------------------------------------+----------------------------------------+
|                  |                          EBS                         |                   S3                   |
+------------------+------------------------------------------------------+----------------------------------------+
|     Paradigm     |            Block storage with file system            |              Object store              |
+------------------+------------------------------------------------------+----------------------------------------+
|    Performance   |                       Very fast                      |                  Fast                  |
+------------------+------------------------------------------------------+----------------------------------------+
|    Redundancy    |    Across multiple servers in an Availability Zone   | Across multiple facilities in a region |
+------------------+------------------------------------------------------+----------------------------------------+
|     Security     |      EBS Encryption - Data Volumes and Snapshots     |               Encryption               |
+------------------+------------------------------------------------------+----------------------------------------+
| Access from web? | No (Accessible if mounted toserver and setup as FTP) |   Yes (Only with proper credentials)   |
+------------------+------------------------------------------------------+----------------------------------------+
| Typical Use case |                  It is a disk drive                  |             Online storage             |
+------------------+------------------------------------------------------+----------------------------------------+

Amazon EC2 Instance store:
- temporary block level storage.
- directly attache to the host computer.
- availability, size is based on instance type.

_____________________________________________________________________________________________________________
				|			Reboot			   |		Stop/Start			  |			Terminate			 |
________________|______________________________|______________________________|______________________________|
Host Computer	|The instance stays on the same|The instance runs on a new    |								 |
				|computer.					   |host computer.				  |				N/A			     |
________________|______________________________|______________________________|______________________________|
Private and 	|Stay the same. 			   |Instance keeps its private IP |								 |
Public Ips		|							   |and gets a new public IP.	  |				N/A			     |
________________|______________________________|______________________________|______________________________|
Elastic IP 		|EIP remains associated with   |EIP remains associated with	  |EIP is dissociated from		 |
addresses (EIP)	|the instance. 		   		   |the instance.				  |the instance.				 |
________________|______________________________|______________________________|______________________________|
Instance store	|Data is preserved			   |Data is erased   			  |Data is erased				 |
Volumes 		|							   |							  |								 |
________________|______________________________|______________________________|______________________________|
EBS Volumes     |Volume is preserved		   |Volume is preserved		      |Volume is deleted by default  |
________________|______________________________|______________________________|______________________________|
Billing|		|Instance billing hour does not|Stop incurring charges as soon|Stop incurring charges when   |
				|changes					   |as state is chaged to stopping|state changes to shutting down|	
________________|______________________________|______________________________|______________________________|


Networking - Amazon Virtual Private Cloud:
- provides a private isolated virtual network on the AWS cloud.
- have complete control over your vpc.
- A subnet defines the range of IP addresses in your VPC. AWS assigns an unique id to each subnet. Subnets can be private(used for resources that wont be accessible over the internet) or public (for resources that will be accessed over the internet). You can launch AWS into the subnet you select. While creating a subnet, you have to choose an AZ and most importantly, a subnet can not span multiple AZs.
- You will have complete control over your virtual networking environment including selection of IP addresses, creation of subnets, configuration of route tables, network access controllers etc.
- Internet Gateway: A component of the VPC that allows communication of the underlying instance with the internet
- Amazon provides 3 features to increase and monitor security in your VPC:
	> Security groups - act as firewall for the associated EC2 instance. Controls in and out traffic of the instance
	> Network access control lists(ACLs) - act as firewall for the associated subnets, contolling in and out traffic at the subnet level.
	> VPN connections.
	
Security and Identity & Access Management:
- AWS follows a Shared Responsibility Model
	+----------+----------------------------------------------------------------------------------------------+
	| Customer |                                         Customer Data                                        |
	|          +----------------------------------------------------------------------------------------------+
	|          |                     Platform, Applcations, Identity and Access Management                    |
	|          +----------------------------------------------------------------------------------------------+
	|          | Operation System, Network and Firewall Configuration                                         |
	|          +-----------------------------+---------------------------+------------------------------------+
	|          | Client-side Data Encryption |   Server Side Encryption  |         Network Traffic Protection |
	|          | and Data Integrity          | (File system and/or Data) |    (Encryption/Integrity/Identity) |
	|          | Authentication              |                           |                                    |
	+----------+-----------------------------+---------------------------+------------------------------------+
	| AWS      |                   Foundation Services: Compute, Storage, Database, Network                   |
	|          +----------------------------------------------------------------------------------------------+
	|          |                        AWS Global Infra: AZs, Regions, Edge Locations                        |
	+----------+----------------------------------------------------------------------------------------------+
- AWS is responsible for the cloud: the foundation services and the global infrastructures (physical environment)
- Customer is responsibe for whatever they put in the cloud: critical customer data.
- However, this model changes with respect to the type of service used. Eg. EC2 instance follows the model. customer has lots of responsibilities like patch or update the softwares, take care of the os etc. On the other hand, in S3 AWS has lots of responsibilities. AWS takes care of the patching and performance instead of the user.
- Another instance of shared responsibility is security groups. AWS provides the structure of security group. User writes the rules and AWS enforces the rules. eg, user writes a rule for a security group saying anyone from anywhere can access any port. This is a rule, not a good one though, but AWS enforces that rule nevertheless. So, write good rules.
- Physical Security of Datacentres:
	> 24/7 trained security staff.
	> AWS DCs in nondescript and undisclosed facilities.
	> 2 factor authentication for authorised staff.
	> Authorisation for DC access.

Security groups:
- AWS provides HTTPS enabled API endpoints to enable secure transmission with your AWS services.
- Security groups are instance firewalls. Users can control how accessible (totally public to completely private) your instances are by configuring the rules.
- Lets consider a 3 tier application: Web Tier, Application Tier and Database Tier.
	+----------+			+------------------+			+---------------+
	| Web Tier |  ------>   | Application Tier |  ------>   | Database Tier	|
	+----------+	  		+------------------+			+---------------+
	     ^
  -------|---------------------------------------------------------------------------[ Security group rules 
	     |												x							  restricting connections to 
  +----------------+									|							  application and database 	
  |    HTTP/S      |							All other internet					  layer ]	
  |Ports 80 and 443|							ports blocked by 
  |only open to the| 							default.
  |internet.	   |
  +----------------+
- We can have different security groups between the Tiers to tighten the rules.


Identity and Access Management:
- Manage IAM users and their access
- Can also use Corporate identities like Active Directory to grow up the security measures instead of creating new accesses: Identity Federation
- Avoid using the root account. Permissions of the root account are immutable.
- When you create an IAM user, you can also create a Access key ID and Secret access key for that user. These can be used by AWS CLI and AWS SDK & API. These two open up a wide range of automation oppotunities within AWS.
- Similar to users, Groups can also be created and permissions of the groups can be controlled. An user can belong to multiple groups. eg, DevOps group (User A, User B), Testing Group (User C, User D).
- Roles: Similar to an user in that it is an AWS identity with permission policies that determine what the identity can and cannot do in AWS. However, instead of being uniquely associated with a person, a role is intended to be assumable by anyone who needs it. Also, a role does not have to have any credentials. Instead if a user is assigned to a role, access keys are created dynamically and provided to the user.
- IMPORTANT: IAM cannot be used to authenticate your operating system or your applications. IAM can be used to authenticate only AWS management console (username & pwd), AWS CLI or SDK (Access key and Secret key) and for authorization in policies.

Authorization Policies:
- To assign permissions to an user, group, role or a resource, you have to create a policy which is a document that explicitly lists all the permissions.
- Policies are written in JSON. Important statements:
	> Effect - Allow/Deny
	> Principle - Who is being given permission?
	> Resource - What type of AWS service is to be acted upon?
	> Condition - Where is the connection coming from, what type of authentication is used?
- Policy generator - will help you build these policies.
- Policy simulator - helps you test the policies you write.
- AWS managed policies - Number of pre-existing policies.
- Customer/Inline policies - Created by us.
- Both Customer/Inline and AWS managed policies are created by the same language and method. However, the prime difference is that an inline policy is tied to a resource, user or group. So if the resource, user or group is deleted then the policy is also deleted. 
- A single IAM policy can be used in multiple places. But the ideal practice is to assign a policy to a group and put the users in that group.
- On the other hand, a role with an assigned policy can in turn be assumed by an user or resource. That particular user or resource assume for a short period of time temporary credentials that allow them to exercise the policy embedded to the IAM role. 
		Eg: 
		> Lets consider a python application that connects to S3. One approach would be to store the AWS credentials required for the connection in the script itself.
		> But this poses a security threat as we could accidently publish the script in git thus exposing the credentials.
		> To avoid this, we can assign a role to the EC2 instance that has the necessary permissions to interact with S3. Now the code inherits the credentials from the role.
		> But, the role can be assumed to an instance only during the creation of the instance.
		> Similarly, users can also assume roles. Once assumed, the users possess the new permissions of the role. Users from different AWS accounts can also assume roles.
- Also some services allow you to assign policy permissions directly to the service. This could be really useful if you want to grant access to cross account or if you want to create more granular set of rules. Supported services include: S3 Bucket policy, SNS topic policy and a lot more.

Security credentials and IAM authorization:
- Temporary security credentials are required and these are generated by the AWS Security Token Service (STS).
- These credentials are short termed but work identical to long term keys.
- They are created dynamically and provided to the user when requested.
- A session created with the STS consists of Access key id, Secret access key and Session Token and a session could last from 15 minutes to 36 hours.
- Use cases of STS: Cross account access, Mobile users, Federation and Key rotation of Amazon EC2 based apps.

IAM Best Practices:
- Delete AWS account(root) access keys.
- Create individual IAM users.
- Use groups to assign permissions to IAM users.
- Grant least privilege.
- Configure a strong password policy.
- Enable MFA for privileged users.
- Use roles for applications that run on EC2 instances.
- Delegate by using roles instead of by sharing credentials.
- Rotate credentials regularly.
- Remove unnecessary users and credentials.
- Use policy conditions for extra security. eg, a particular action is allowed only if the user is authenticated from an ip address.
- Monitor activity in your AWS account. AWS CloudTrail that will give you details of the activity in your account.

AWS Databases:
- AWS managed database services: DynamoDB, ElastiCache, RDS, Redshift, Database Migration Service.

Amazon RDS:
- Cost efficient and resizable capacity.
- Currently supports 6 different relational database engines: Amazon Aurora, MySQL, MariaDB, Microsoft SQL Server, Oracle and PostgreSQL. Depending on the engine you select, RDS has some additional replication features available.
- Database instance - building blocks of RDS. They are and isolated database environment in the cloud. They can contain multiple user created databases. Database instances can be modified.
- When automatic backups(include transaction logs too) are turned on (default), RDS takes a full daily snapshot of your data. This is done during a backup window that you configure. Backups help restore your database to a point in time. You can choose a retention period of upto 35 days (default: 1 day).
- Manual snapshots are also possible. Lets you create a new database instance from the snapshot. They are persisted in S3 and exist until the user deletes them.
- Cross-Region snapshots are also available for all supported RDS engines. These provide a backup for disaster recovery and can also be used as a base for region level migration.
- RDS Security: Method used to secure the RDS depends on the task to be performed. 
	> Run your DB instance in an Amazon VPC - to manage network access
	> Use IAM policies to grant permission/access to RDS users/resources - can control who can create, delete or modify the database instances etc.
	> Security groups - which IP addresses or EC2 instances can connect to the database
	> Use SSL connections with Databases
	> RDS encryption - to encrypt not only the data in the database but also the snapshots. Use network encryption and transfer data encryption (TDB) with Oracle DB and Microsoft SQL Servers.
	> Use security features of your DB engines to control access to your instances.
- Multi-AZ RDS Deployments:
	> When you provision a Multi-AZ DB instance, RDS automatically creates a primary instance and synchronously replicates to another instance in a different AZ in the same region. When there is a failure in any one of the AZ, AWS automatically performs a failover to the standby so that user can resume DB operations as soon as the failover is complete. Endpoint to your DB remains same even after failover.
- DB Parameter and Option groups: To customise the configurations used by the underlying engine in the instance (we dont have access to it otherwise) 
	> DB Parameter group: Contain engine configuration values that can be applied to one or more DB instances with same engine and version. RDS applies a default param group when you create DB instance, which contains defaults for specific DB engine and instance class of the DB instance.
	> DB Options group: Tools that simplify Database management. Currently available for Microsoft SQL Server, Oracle and MySQL 5.6 DB instances.
- RDS Best Practices:
	> Monitor your memory, CPU and storage usage.
	> Use Multi-AZ deployments to automatically provision and maintain a synchronous standby in a different AZ.
	> Enable automatic backups and the backup window for that is set during a low period in the Write Volumes.
	> Set a TTL of less than 30 seconds if your client application is caching the DNS data of your DB instance.
	> Test failover of your DB instance.

DynamoDB: 
- High performant, fully scalable, no sql database service. 
- There is no limit on the size of the data.
- Fast predictable performance using SSDs
- Need to specify the primary key to create, delete or update any entry.
- 2 kinds of primary key - Partition key & Composite key
	> Partition key: simple single component. determines the partition where the item is stored.
	> Composite key: partition key + sort key. partition key performs its functions. all items with the same partition key are stored together in a sorted manner by the sort key. Two values with the same partition key cannot have the same sort key.
- Each table can have upto 5 local secondary indexes. LSI come into play when we want to query a non-key value.
- Global Secondary Index: An index with the partition key and sort key different from that of the primary table.
- When you create or update a table, you specify how much provisioned throughput capacity you need for reads and writes. DynamoDB automatically allocates the necessary machine resources to meet your needs. The throughput is measured in capacity units.
	> Read capacity unit = 1 strongly consistent read/sec as large as 4Kb (or) 2 eventually consistent reads/sec as large as 4Kb 
	> Write Capacity unit = 1 write/sec for items as large as 1Kb.
- Supported Operations - Query & Scan
	> Query: Query a table using partition key, optional sort key or secondary index. It is the most efficient way to retrieve items from a table or secondary index
	> Scan: Scan a table or a secondary index. Scan reads every item - slower than querying.
	
RDS vs DynamoDB:

+------------------+------------------------------------------+---------------------------------------------+
|                  |             Relational (RDS)             |               NoSQL (DynamoDB)              |
+------------------+------------------------------------------+---------------------------------------------+
| Application Type | > Existing Database apps                 | > New web-scale apps                        |
|                  | > Business process-centric apps          | > Large number of small reads and writes    |
+------------------+------------------------------------------+---------------------------------------------+
|   Application    | > Relational data models, transactions   | > Simple data models, transactions          |
|  Characteristics | > Complex queries, joins and updates     | > Range queries, simple updates             |
+------------------+------------------------------------------+---------------------------------------------+
|      Scaling     | > Application or DBA-architected         | Seamless, on-demand scaling based           |
|                  |   (clustering, partitions, sharding)     | on application requirements                 |
+------------------+------------------------------------------+---------------------------------------------+
|        QoS       | > Performance - depends on data model,   | > Performance - Automatically optimized by  |
|                  | indexing, query and storage optimization | the system                                  |
|                  | > Reliabitlity and availability          | > Reliabitlity and availability             |
|                  | > Durability                             | > Durability                                |
+------------------+------------------------------------------+---------------------------------------------+

Database Considerations:

+--------------------------------+---------------------------------------------+
| If you need                    | Consider using                              |
+--------------------------------+---------------------------------------------+
| A relational database service  | RDS                                         |
| with minimal administration    | > Choice of Amazon Aurora, MySQL, MariaDB,  |
|                                | Microsoft SQL Server, Oracle and PostgreSQL |
|                                | > Scale, compute ad storage                 |
|                                | > Multi-AZ availability                     |
+--------------------------------+---------------------------------------------+
| A fast, highly scalable,       | DynamoDB                                    |
| NoSQL database service         | > Extremely fast performance                |
|                                | > Seamless scalability and reliability      |
|                                | > Low cost                                  |
+--------------------------------+---------------------------------------------+
| A database you can manage      | Your choice of AMIs on EC2 and              |
| on your own                    | Amazon EBS that provide scale               |
|                                | compute and storage, complete control       |
|                                | over instances and more.                    |
+--------------------------------+---------------------------------------------+


Elasticity and Management Tools:

- Multiple EC2 instances (autoscaling group) will be managed by the load balancer. The EC2 instances will send metrics like latency, utilization etc to CloundWatch. Alarms can be set in CloundWatch to be triggered if any value exceeds the set value. This alarm triggers an autoscaling policy. This creates an additional instance. Once this instance is up and running, AutoScaling adds it to the instance group and registers with the load balancer.

Auto Scaling:
- Automatically scale EC2 capacity.
- Well suited for applications with variable usage.
- AutoScaling is free of charge.
- Benefits:
	> Better fault tolerance.
	> Better availability.
	> Better cost management.
- Core concepts:
	> What? - Launch configuration
	> Where? - Autoscaling groups 
	> When? - Autoscale Lifecycle
- Launch configration: A template that and autoscaling group uses to launch instances. Specified when launching an autoscaling group. You can specify: AMI ID, Instance type, Key pairs, Security groups, Block device mapping and User data. It is immutable.If you want to change then you would have to create a new autoscaling group and associate it with the group. This will not affect the existing instances. But any new instance launched thereafter will use the new configuration.
- Autoscaling groups: Contains collection of EC2 instances that share similar characteristics. All instances in a group will be treated as one logical grouping for scaling and management. Can set a few values for a group:
	> Minimum value: a must have minimum number of instances in the group.
	> Maximum value: most number of instances we can have inside a group despite any scaling operations.
	> Desired capacity: Our autoscaling group is always working towards the desired capacity. If desired capacity is greated than current count then group looks up the configurations and launches a new instance and vice versa.

Elastic Load Balancing:
- Distributes traffic across multiple instances.
- Supports health checks to detect unhealth instances. Thus higher level of fault tolerance. Unhealthy instances wont receive any input requests. Healt check is an ongoing process. Health checks can be used in conjunction with Autoscaling to terminate and remove unhealthy instances and create new ones. 
- Can span multiple AZs.
- Supports the routing and load balancing of HTTP, HTTPS and TCP traffic to the instances.
- Load Balancer types (Can enable HTTPS in both):
	> Internet facing: LB accepts requests from clients coming directly from the internet.
	> Internal: Only requests generated within our VPC.
	
CloudWatch:
- A monitoring service for AWS cloud resources and the application you run on AWS.
- Visibility into large set of default metrics like utilization, operational performances and overall demand patterns.
- By default, CW is not capable of collecting metrics from our OS or applications. If we want we can push those metrics from the sources in the form of custom metrics to be monitored using the API or CLI. However, certain AWS services push their metrics to CW on their own.
- CW monitoring is accessible to us via the Console, API, SDK or CLI.
- Alarms can be set in CW based on threshold we set. Alarms will be triggered only for sustained changes. This can be used to trigger e-mails or autoscaling policy.
- Monitoring is done in a 5 minute interval. Detailed monitoring does it in a 1 minute interval.

Trusted Advisor:
- Best practices recommendation engine.
- Performs checks in 4 categories: cost optimization, security, fault tolerance and performance improvement.
- Result outputs are displayed in a console.
- Colour indicators: Red - action recommended, Yellow - might want to investigate it, Green - no problem found
- Helps in cost optimization too by identifying idle and unused resources. Example tests: EC2 Reserved instances, Low Utilisation, Idle LB, Underutilised, Unassociated IP addresses, Idle DB instances.
- Helps improve the security of our applications. Example tests: Security groups, AWS IAM use, S3 Bucket permissions, MFA on root account, AWS IAM password policy, RDS Security Group Access Risk
- Fault Tolerance tests: EBS snapshots, LB Optimisation, Auto Scaling Group resources, RDS Multi-AZ, Route 53 Name Server Delegations, ELB Connection Draining
- Performance Improvement tests: High Utilisation instances, Service Limits, Large number of rules in EC2 Security group, Over utilised EBS Magnetic Volumes, EC2 to EBS throughput optimization, CloudFront alternate domain names.